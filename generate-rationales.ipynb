{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb06a35",
   "metadata": {
    "_cell_guid": "01a4780a-9aee-49d7-843c-a3cb7da08d92",
    "_uuid": "646593ac-d02f-49b6-9d10-debc176e7df2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-21T09:29:15.380837Z",
     "iopub.status.busy": "2024-07-21T09:29:15.380458Z",
     "iopub.status.idle": "2024-07-21T09:30:20.345852Z",
     "shell.execute_reply": "2024-07-21T09:30:20.344434Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 64.974228,
     "end_time": "2024-07-21T09:30:20.348405",
     "exception": false,
     "start_time": "2024-07-21T09:29:15.374177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/bitsandbytes-0.42.0-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/accelerate-0.27.2-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/transformers-4.38.1-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/optimum-1.17.1-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedd1b06",
   "metadata": {
    "_cell_guid": "e0aebef2-97fb-416d-9fcd-94e6ff8a4307",
    "_uuid": "8c29a3ce-2ea9-4608-86a6-28a2ee774ccc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-21T09:30:20.359680Z",
     "iopub.status.busy": "2024-07-21T09:30:20.359358Z",
     "iopub.status.idle": "2024-07-21T09:30:28.383753Z",
     "shell.execute_reply": "2024-07-21T09:30:28.382733Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.032728,
     "end_time": "2024-07-21T09:30:28.386032",
     "exception": false,
     "start_time": "2024-07-21T09:30:20.353304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from memotion_utility import load_data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5226f26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T09:30:28.396688Z",
     "iopub.status.busy": "2024-07-21T09:30:28.396218Z",
     "iopub.status.idle": "2024-07-21T09:30:28.401082Z",
     "shell.execute_reply": "2024-07-21T09:30:28.400110Z"
    },
    "papermill": {
     "duration": 0.01237,
     "end_time": "2024-07-21T09:30:28.403112",
     "exception": false,
     "start_time": "2024-07-21T09:30:28.390742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSV_FILE = '/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/labels.csv'\n",
    "captions = '/kaggle/input/memotion-with-captions/caption_BLIP.csv'\n",
    "ROOT_DIR = '/kaggle/input/memotion-dataset-7k/memotion_dataset_7k/images'\n",
    "downsample = False\n",
    "max_new_token = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73485030",
   "metadata": {
    "_cell_guid": "bf0e7549-f9a7-40d3-9aa5-d6145eb63475",
    "_uuid": "a2757e4c-c45d-468d-a2c4-d3fd93c2ed28",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-21T09:30:28.414088Z",
     "iopub.status.busy": "2024-07-21T09:30:28.413781Z",
     "iopub.status.idle": "2024-07-21T09:34:31.530508Z",
     "shell.execute_reply": "2024-07-21T09:34:31.529697Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 243.125101,
     "end_time": "2024-07-21T09:34:31.532982",
     "exception": false,
     "start_time": "2024-07-21T09:30:28.407881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6008749acf58436ca1bf338e1e5333cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# MODEL_PATH = \"/kaggle/input/gemma/transformers/7b-it/2\"\n",
    "# MODEL_PATH = \"/kaggle/input/gemma/transformers/2b-it/2\"\n",
    "# MODEL_PATH = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n",
    "# MODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n",
    "MODEL_PATH = \"/kaggle/input/llama-2/pytorch/13b-chat-hf/1\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True,\n",
    "    quantization_config=quantization_config,\n",
    "    pretraining_tp=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186a6449",
   "metadata": {
    "_cell_guid": "04085bc3-70d0-4355-87d2-b9cae6d6f86f",
    "_uuid": "62c98438-d134-4255-bc2c-f3129e7b58db",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:31.551120Z",
     "iopub.status.busy": "2024-07-21T09:34:31.550020Z",
     "iopub.status.idle": "2024-07-21T09:34:31.555597Z",
     "shell.execute_reply": "2024-07-21T09:34:31.554388Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017968,
     "end_time": "2024-07-21T09:34:31.559948",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.541980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/kaggle/input/memotion-with-captions/memotion_dataset_with_captions_BLIP.csv')\n",
    "# def preprocess(df):\n",
    "#     df = df.drop('Unnamed: 0', axis=1)\n",
    "#     df = df.sample(frac=1).reset_index(drop=True)\n",
    "#     df['offensive'] = np.where(df['offensive'] == 'not_offensive', 'not_offensive', 'offensive')\n",
    "\n",
    "#     df['offensive'] = df['offensive'].map({\n",
    "#         'not_offensive': 0, \n",
    "#         'offensive': 1\n",
    "#     })\n",
    "#     return df\n",
    "# df = preprocess(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be2d74b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:31.574256Z",
     "iopub.status.busy": "2024-07-21T09:34:31.573970Z",
     "iopub.status.idle": "2024-07-21T09:34:31.870188Z",
     "shell.execute_reply": "2024-07-21T09:34:31.868898Z"
    },
    "papermill": {
     "duration": 0.305666,
     "end_time": "2024-07-21T09:34:31.872431",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.566765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : \n",
      " label\n",
      "1    3079\n",
      "0    1951\n",
      "Name: count, dtype: int64\n",
      "val : \n",
      " label\n",
      "1    342\n",
      "0    217\n",
      "Name: count, dtype: int64\n",
      "test : \n",
      " label\n",
      "1    856\n",
      "0    542\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df,val_df,test_df = load_data(CSV_FILE,downsample = downsample,captions = captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22957ffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:31.886194Z",
     "iopub.status.busy": "2024-07-21T09:34:31.885870Z",
     "iopub.status.idle": "2024-07-21T09:34:31.893782Z",
     "shell.execute_reply": "2024-07-21T09:34:31.892853Z"
    },
    "papermill": {
     "duration": 0.017955,
     "end_time": "2024-07-21T09:34:31.895828",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.877873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display(df,index):\n",
    "    row = df.iloc[index]\n",
    "    \n",
    "    # Load the image\n",
    "    img_name = df.iloc[index]['image_name']\n",
    "    img_path = os.path.join(ROOT_DIR,img_name)\n",
    "    img = mpimg.imread(img_path)\n",
    "    \n",
    "    # Extract the OCR text and caption\n",
    "    text_ocr = row['text']\n",
    "    caption = row['caption']\n",
    "    offensive = row['label']\n",
    "    \n",
    "    # Plot the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Display OCR text and caption\n",
    "    plt.title(f\"name:{img_name}\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc850cdf",
   "metadata": {
    "_cell_guid": "201e1a73-ef80-4fce-9ab9-840fde52ac50",
    "_uuid": "1459da6d-39b4-4e86-b0b2-783e8f5c875e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:31.907620Z",
     "iopub.status.busy": "2024-07-21T09:34:31.907347Z",
     "iopub.status.idle": "2024-07-21T09:34:31.915142Z",
     "shell.execute_reply": "2024-07-21T09:34:31.914250Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015898,
     "end_time": "2024-07-21T09:34:31.917079",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.901181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(df,index):\n",
    "    row = df.iloc[index]\n",
    "    text_ocr = row['text']\n",
    "    caption = row['caption']\n",
    "    offensive = row['label']\n",
    "    y = \"Offensive\" if offensive == 1 else \"Not Offensive\"\n",
    "\n",
    "    system_prompt = \"\"\"You have been specially designed to perform abductive reasoning for the harmful meme detection task. Your primary function is that, according to a Harmfulness label about an Image with a text embedded, please provide me a streamlined rationale, without explicitly indicating the label, why it is classified as the given Harmfulness label.\n",
    "The image and the textual content in the meme are often uncorrelated, but its overall semantics is presented holistically. Thus it is important to note that you are prohibited from relying on your own imagination, as your goal is to provide the most accurate and reliable rationale possible\n",
    "so that people can infer the harmfulness according to your reasoning about the background context and relationship between the given text and image caption\n",
    "\"\"\"\n",
    "    user_message = f\"Given a Text: {text_ocr}, which is embedded in an Image: {caption}; and a harmfulness label {y}, please give me a streamlined rationale associated with the meme, without explicitly indicating the label, for how it is reasoned as {y}.\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "{ system_prompt }\n",
    "<</SYS>>\n",
    "\n",
    "{ user_message } [/INST]\n",
    "\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90290179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:31.930343Z",
     "iopub.status.busy": "2024-07-21T09:34:31.929978Z",
     "iopub.status.idle": "2024-07-21T09:34:31.934692Z",
     "shell.execute_reply": "2024-07-21T09:34:31.933842Z"
    },
    "papermill": {
     "duration": 0.016755,
     "end_time": "2024-07-21T09:34:31.939101",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.922346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display(train_df,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f639485f",
   "metadata": {
    "_cell_guid": "138b371c-f998-4ac6-9f20-f10ddde04029",
    "_uuid": "2686be5b-e240-4cf2-adc3-24ba9663496f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:31.954971Z",
     "iopub.status.busy": "2024-07-21T09:34:31.954662Z",
     "iopub.status.idle": "2024-07-21T09:34:31.958813Z",
     "shell.execute_reply": "2024-07-21T09:34:31.957916Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014371,
     "end_time": "2024-07-21T09:34:31.961027",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.946656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(build_prompt(train_df,19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab02a3f2",
   "metadata": {
    "_cell_guid": "a6dc193d-cada-43c7-a8f5-42f42c4c3c6b",
    "_uuid": "da3d1572-0918-4eb1-b6a9-68c344209b8f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:31.976342Z",
     "iopub.status.busy": "2024-07-21T09:34:31.975973Z",
     "iopub.status.idle": "2024-07-21T09:34:31.980656Z",
     "shell.execute_reply": "2024-07-21T09:34:31.979753Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014215,
     "end_time": "2024-07-21T09:34:31.982528",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.968313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "# n = 19\n",
    "# input_text = build_prompt(train_df,n)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "# outputs = model.generate(input_ids,max_new_tokens=max_new_token)\n",
    "# predicted_answer = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "# predicted_answer = predicted_answer[len(input_text)-1:].strip()\n",
    "# print(predicted_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489595af",
   "metadata": {
    "papermill": {
     "duration": 0.005093,
     "end_time": "2024-07-21T09:34:31.992954",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.987861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split data in batch to generate in multiple run (because cannot do all in one run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ff775e",
   "metadata": {
    "_cell_guid": "5d0efe60-dd55-455e-b629-5c030fa89ed9",
    "_uuid": "d02e4624-64f7-4f61-9726-1740bfd7ddd4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:32.005908Z",
     "iopub.status.busy": "2024-07-21T09:34:32.004972Z",
     "iopub.status.idle": "2024-07-21T09:34:32.013904Z",
     "shell.execute_reply": "2024-07-21T09:34:32.012876Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017598,
     "end_time": "2024-07-21T09:34:32.015872",
     "exception": false,
     "start_time": "2024-07-21T09:34:31.998274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(df,subset_indices):\n",
    "    \"\"\"\n",
    "    Generate rationales for a subset indices of the data frame\n",
    "    \"\"\"\n",
    "    rationales = []\n",
    "    for index in tqdm(subset_indices, desc=\"Generating rationales\"):\n",
    "        input_text = build_prompt(train_df,index)\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "        outputs = model.generate(input_ids, max_new_tokens=max_new_token)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        # Extract the rationale by removing the input text from the generated output\n",
    "        rationale = generated_text[len(input_text)-1:].strip()\n",
    "        rationales.append(rationale)\n",
    "        \n",
    "    new_df = df.iloc[subset_indices][['image_name']].copy()\n",
    "    new_df['rationale'] = rationales\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c6ac3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:32.028419Z",
     "iopub.status.busy": "2024-07-21T09:34:32.027710Z",
     "iopub.status.idle": "2024-07-21T09:34:32.037625Z",
     "shell.execute_reply": "2024-07-21T09:34:32.036780Z"
    },
    "papermill": {
     "duration": 0.019304,
     "end_time": "2024-07-21T09:34:32.040542",
     "exception": false,
     "start_time": "2024-07-21T09:34:32.021238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 1: 503\n",
      "Subset 2: 503\n",
      "Subset 3: 503\n",
      "Subset 4: 503\n",
      "Subset 5: 503\n",
      "Subset 6: 503\n",
      "Subset 7: 503\n",
      "Subset 8: 503\n",
      "Subset 9: 503\n",
      "Subset 10: 503\n"
     ]
    }
   ],
   "source": [
    "total_indices = len(train_df)\n",
    "\n",
    "num_subsets = 10\n",
    "subset_size = total_indices // num_subsets\n",
    "\n",
    "indices = np.arange(total_indices)\n",
    "subsets = [indices[i * subset_size:(i + 1) * subset_size] for i in range(num_subsets)]\n",
    "\n",
    "# If there are remaining indices, distribute them among the subsets\n",
    "remainder = total_indices % num_subsets\n",
    "for i in range(remainder):\n",
    "    subsets[i] = np.append(subsets[i], indices[num_subsets * subset_size + i])\n",
    "\n",
    "# Print the subsets\n",
    "for i, subset in enumerate(subsets):\n",
    "    print(f\"Subset {i + 1}: {len(subset)}\")\n",
    "\n",
    "# Example: Accessing the first subset\n",
    "first_subset_indices = subsets[0]\n",
    "first_subset = train_df.iloc[first_subset_indices]\n",
    "\n",
    "#first_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b858986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T09:34:32.058339Z",
     "iopub.status.busy": "2024-07-21T09:34:32.057690Z",
     "iopub.status.idle": "2024-07-21T14:08:16.778377Z",
     "shell.execute_reply": "2024-07-21T14:08:16.777239Z"
    },
    "papermill": {
     "duration": 16424.74974,
     "end_time": "2024-07-21T14:08:16.798369",
     "exception": false,
     "start_time": "2024-07-21T09:34:32.048629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rationales:   0%|          | 0/559 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "2024-07-21 09:34:36.593246: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-21 09:34:36.593349: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-21 09:34:36.713586: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Generating rationales: 100%|██████████| 559/559 [4:33:44<00:00, 29.38s/it]\n"
     ]
    }
   ],
   "source": [
    "def step(n):\n",
    "\n",
    "    df_new = generate(train_df, subsets[n])\n",
    "    #display(df_new)\n",
    "    df_new.to_csv(f'/kaggle/working/rationales_train_{n}.csv', index=False)\n",
    "    \n",
    "#step(9)\n",
    "    \n",
    "# df_2 = generate(df_train, subsets[1])\n",
    "# df_3 = generate(df_train, subsets[2])\n",
    "# df_4 = generate(df_train, subsets[3])\n",
    "# df_5 = generate(df_train, subsets[4])\n",
    "# df_6 = generate(df_train, subsets[5])\n",
    "# df_7 = generate(df_train, subsets[6])\n",
    "# df_8 = generate(df_train, subsets[7])\n",
    "# df_9 = generate(df_train, subsets[8])\n",
    "# df_10 = generate(df_train, subsets[9])\n",
    "\n",
    "df_val = generate(val_df,range(len(val_df)))\n",
    "df_val.to_csv(f'/kaggle/working/rationales_val.csv', index=False)\n",
    "#df_test = generate(test_df,range(len(test_df)))\n",
    "#df_new.to_csv(f'/kaggle/working/rationales_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 531544,
     "sourceId": 973292,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5174910,
     "sourceId": 8835158,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 164836055,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 186426962,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 735,
     "modelInstanceId": 3097,
     "sourceId": 4302,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16747.627815,
   "end_time": "2024-07-21T14:08:20.277192",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-21T09:29:12.649377",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "18c0a6546e054c2f8bb463c209c8b779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1a30d49b90c842688a65e588d7a74f6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21cf024b64ab4e2c9a6971ba21e50c3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4775e307a97341459ad266038055fd71",
       "placeholder": "​",
       "style": "IPY_MODEL_fbe8557bd0054c9cb7dacf81c7f27859",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "4775e307a97341459ad266038055fd71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6008749acf58436ca1bf338e1e5333cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_21cf024b64ab4e2c9a6971ba21e50c3c",
        "IPY_MODEL_df870204538545e5afe11cad70a5edc4",
        "IPY_MODEL_e5a704c2f60a4c17a8fdd84f94fed4df"
       ],
       "layout": "IPY_MODEL_d836f875cf4145c8bca8bf83a9070eb1"
      }
     },
     "74bffd37db0a401f9bb1ead8b8ff4b41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d836f875cf4145c8bca8bf83a9070eb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df870204538545e5afe11cad70a5edc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f571ee2df1284bb6aa0edabced834923",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74bffd37db0a401f9bb1ead8b8ff4b41",
       "value": 3.0
      }
     },
     "e5a704c2f60a4c17a8fdd84f94fed4df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1a30d49b90c842688a65e588d7a74f6d",
       "placeholder": "​",
       "style": "IPY_MODEL_18c0a6546e054c2f8bb463c209c8b779",
       "value": " 3/3 [04:00&lt;00:00, 75.62s/it]"
      }
     },
     "f571ee2df1284bb6aa0edabced834923": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fbe8557bd0054c9cb7dacf81c7f27859": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
